{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIDS_EvaluateClassifiers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Network-based Intrusion Detection System\n",
        "*Evaluation of Classifiers (Scikit Learn)*\n",
        "\n",
        "**Dataset** [NSL-KDD](https://www.unb.ca/cic/datasets/nsl.html)\n",
        "\n",
        "**Classification**\n",
        "\n",
        "1. Binary (Benign and Attack classes)\n",
        "2. Multi-class (Benign, Probe, DoS, U2R, and R2L classes)\n",
        "\n",
        "**Classifiers**\n",
        "\n",
        "1. Decision Tree\n",
        "2. K-Nearest Neighbours\n",
        "3. Classification and Regression Tree\n",
        "4. Random Forest\n",
        "5. AdaBoost\n",
        "6. Logistics Regression\n",
        "7. Linear Discriminant Analysis\n",
        "8. Quadratic Discriminant Analysis\n",
        "9. Multi-Layer Perceptron\n",
        "10. Linear SVC\n",
        "\n",
        "**Metrics**\n",
        "\n",
        "1. Acccuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. F1-score\n",
        "5. Execution Time\n",
        "\n",
        "Metrics and Confusion Matrices: https://github.com/BenoyRNair/NIDS/blob/main/NIDS_EvaluateClassifiers.pdf\n",
        "\n",
        "\n",
        "[This notebook](https://github.com/BenoyRNair/NIDS_MultipleClassifiers) was tested in ***Google Colab***."
      ],
      "metadata": {
        "id": "RYsM3uctEoC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Credits\n",
        "\n",
        "1. Adopted from [Predicting Network Attacks](https://colab.research.google.com/github/smlra-kjsce/Cyber-ML-DL-101/blob/master/Predicting_Network_Attacks.ipynb)\n",
        "2. [Scikit Learn](https://scikit-learn.org/)\n",
        "3. [Alive progress](https://pypi.org/project/alive-progress/)"
      ],
      "metadata": {
        "id": "p-XdNK0EFk_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Licence\n",
        "@Author [Benoy R Nair](https://github.com/BenoyRNair)\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "\n",
        "You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied See the License for the specific language governing permissions and limitations under the License."
      ],
      "metadata": {
        "id": "-EPiXy5ERTE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "iuj7fTOOMGED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhMHG4umERZe"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "# Download NSL-KDD.zip from the website\n",
        "!wget http://205.174.165.80/CICDataset/NSL-KDD/Dataset/NSL-KDD.zip\n",
        "# alternatively if the above link does not work\n",
        "#!wget -O NSL-KDD.zip https://cloudstor.aarnet.edu.au/plus/s/P13PYzoU5olpDwz/download\n",
        "!wget -O name.txt http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types\n",
        "#!wget -O name.txt http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\n",
        "!unzip NSL-KDD.zip\n",
        "# To show the progress of execution with the different classifiers\n",
        "!pip install alive-progress"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_list = ['Binary', 'Multi-class']\n",
        "\n",
        "#@markdown Specify the classification (Binary or Multi-class).\n",
        "\n",
        "#@markdown Binary: Benign and Attack classes\n",
        "\n",
        "#@markdown Multi-class: Benign, Probe, DoS, U2R, and R2L classes\n",
        "\n",
        "\n",
        "from ipywidgets import interactive\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def model(CLASSIFICATION):\n",
        "  return CLASSIFICATION\n",
        "\n",
        "classification_widget = interactive (model, CLASSIFICATION=classification_list)\n",
        "display (classification_widget)"
      ],
      "metadata": {
        "id": "0N9KgJ6lhFd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "qVYh3srAfeXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset_root = '/content'\n",
        "train_file = os.path.join(dataset_root, 'KDDTrain+.txt')\n",
        "test_file = os.path.join(dataset_root, 'KDDTest+.txt')\n",
        "\n",
        "header_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack_type', 'success_pred']\n",
        "\n",
        "col_names = np.array(header_names)\n",
        "\n",
        "nominal_idx = [1, 2, 3]\n",
        "binary_idx = [6, 11, 13, 14, 20, 21]\n",
        "numeric_idx = list(set(range(41)).difference(nominal_idx).difference(binary_idx))\n",
        "\n",
        "nominal_cols = col_names[nominal_idx].tolist()\n",
        "binary_cols = col_names[binary_idx].tolist()\n",
        "numeric_cols = col_names[numeric_idx].tolist()\n",
        "\n",
        "category = defaultdict(list)\n",
        "category['benign'].append('normal')\n",
        "\n",
        "name = os.path.join(dataset_root,'name.txt')\n",
        "\n",
        "attack_mapping = {'apache2': 'dos',\n",
        " 'back': 'dos',\n",
        " 'buffer_overflow': 'u2r',\n",
        " 'ftp_write': 'r2l',\n",
        " 'guess_passwd': 'r2l',\n",
        " 'httptunnel': 'r2l',\n",
        " 'imap': 'r2l',\n",
        " 'ipsweep': 'probe',\n",
        " 'land': 'dos',\n",
        " 'loadmodule': 'u2r',\n",
        " 'mailbomb': 'dos',\n",
        " 'mscan': 'probe',\n",
        " 'multihop': 'r2l',\n",
        " 'named': 'r2l',\n",
        " 'neptune': 'dos',\n",
        " 'nmap': 'probe',\n",
        " 'normal': 'benign',\n",
        " 'perl': 'u2r',\n",
        " 'phf': 'r2l',\n",
        " 'pod': 'dos',\n",
        " 'portsweep': 'probe',\n",
        " 'processtable': 'dos',\n",
        " 'ps': 'u2r',\n",
        " 'rootkit': 'u2r',\n",
        " 'saint': 'probe',\n",
        " 'satan': 'probe',\n",
        " 'sendmail': 'r2l',\n",
        " 'smurf': 'dos',\n",
        " 'snmpgetattack': 'r2l',\n",
        " 'snmpguess': 'r2l',\n",
        " 'spy': 'r2l',\n",
        " 'sqlattack': 'u2r',\n",
        " 'teardrop': 'dos',\n",
        " 'udpstorm': 'dos',\n",
        " 'warezclient': 'r2l',\n",
        " 'warezmaster': 'r2l',\n",
        " 'worm': 'dos',\n",
        " 'xlock': 'r2l',\n",
        " 'xsnoop': 'r2l',\n",
        " 'xterm': 'u2r'}\n",
        "\n",
        "attack_mapping_2 = attack_mapping.copy()\n",
        "\n",
        "for key, value in attack_mapping_2.items():\n",
        "  if key != 'normal':\n",
        "    attack_mapping_2.update({key:'attack'})\n",
        "\n",
        "selected_classification = classification_widget.result\n",
        "\n",
        "train_df = pd.read_csv(train_file, names=header_names)\n",
        "train_df['attack_category'] = train_df['attack_type'].map(lambda x: attack_mapping[x] if classification_widget.result == 'Multi-class' else attack_mapping_2[x])\n",
        "train_df.drop(['success_pred'], axis=1, inplace=True)\n",
        "    \n",
        "test_df = pd.read_csv(test_file, names=header_names)\n",
        "test_df['attack_category'] = test_df['attack_type'].map(lambda x: attack_mapping[x] if classification_widget.result == 'Multi-class' else attack_mapping_2[x])\n",
        "test_df.drop(['success_pred'], axis=1, inplace=True)\n",
        "\n",
        "train_attack_types = train_df['attack_type'].value_counts()\n",
        "train_attack_cats = train_df['attack_category'].value_counts()\n",
        "\n",
        "test_attack_types = test_df['attack_type'].value_counts()\n",
        "test_attack_cats = test_df['attack_category'].value_counts()\n",
        "\n",
        "train_df[binary_cols].describe().transpose()\n",
        "train_df.groupby(['su_attempted']).size()\n",
        "\n",
        "train_df['su_attempted'].replace(2, 0, inplace=True)\n",
        "test_df['su_attempted'].replace(2, 0, inplace=True)\n",
        "train_df.groupby(['su_attempted']).size()\n",
        "\n",
        "train_df.groupby(['num_outbound_cmds']).size()\n",
        "\n",
        "train_df.drop('num_outbound_cmds', axis = 1, inplace=True)\n",
        "test_df.drop('num_outbound_cmds', axis = 1, inplace=True)\n",
        "numeric_cols.remove('num_outbound_cmds')\n",
        "\n",
        "train_Y = train_df['attack_category']\n",
        "train_x_raw = train_df.drop(['attack_category','attack_type'], axis=1)\n",
        "test_Y = test_df['attack_category']\n",
        "test_x_raw = test_df.drop(['attack_category','attack_type'], axis=1)\n",
        "\n",
        "combined_df_raw = pd.concat([train_x_raw, test_x_raw])\n",
        "combined_df = pd.get_dummies(combined_df_raw, columns=nominal_cols, drop_first=True)\n",
        "\n",
        "train_x = combined_df[:len(train_x_raw)]\n",
        "test_x = combined_df[len(train_x_raw):]\n",
        "\n",
        "dummy_variables = list(set(train_x)-set(combined_df_raw))\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "durations = train_x['duration'].values.reshape(-1, 1)\n",
        "standard_scaler = StandardScaler().fit(durations)\n",
        "scaled_durations = standard_scaler.transform(durations)\n",
        "#pd.Series(scaled_durations.flatten()).describe()"
      ],
      "metadata": {
        "id": "fu77fr7jfaii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Classifiers (NIDS)\n",
        "\n",
        "Classifier training & prediction\n",
        "\n",
        "Review confusion matrix for each classifier"
      ],
      "metadata": {
        "id": "SKYEg2l_gNNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "models = []\n",
        "models.append(('DT', DecisionTreeClassifier(random_state=17)))\n",
        "models.append(('KNN', KNeighborsClassifier(n_neighbors=9)))\n",
        "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
        "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
        "models.append(('ABoost', AdaBoostClassifier()))\n",
        "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
        "models.append(('MLP', MLPClassifier()))\n",
        "models.append(('LinSVC', LinearSVC()))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "from alive_progress import alive_bar\n",
        "import time\n",
        "\n",
        "metrics_summary = {}\n",
        "\n",
        "if classification_widget.result != selected_classification:\n",
        "  print ('Classification has been changed.\\nRun the \\'Preprocessing\\' section again.')\n",
        "else:\n",
        "  xlabel = 'Predicted'\n",
        "  ylabel = 'Actual'\n",
        "  title = 'Confusion Matrix'\n",
        "\n",
        "  if classification_widget.result == 'Multi-class':\n",
        "    tickLabels = ['benign', 'probe','dos','u2r','r2l']\n",
        "    figsize=(15, 12)\n",
        "  else:\n",
        "    tickLabels = ['benign', 'attack']\n",
        "    figsize=(5, 4)\n",
        "\n",
        "  print (\"\\n\")\n",
        "  \n",
        "  with alive_bar(len (models), force_tty = True, stats = False) as bar:\n",
        "    for name, classifier in models:\n",
        "      bar.title_length = 10\n",
        "      bar.title = name\n",
        "      start_time = time.time()\n",
        "\n",
        "      classifier.fit(train_x, train_Y)\n",
        "      pred_y = classifier.predict(test_x)\n",
        "\n",
        "      delta = time.time() - start_time\n",
        "\n",
        "      results = confusion_matrix(test_Y, pred_y)\n",
        "      error = zero_one_loss(test_Y, pred_y)\n",
        "      accuracy = accuracy_score (test_Y, pred_y)\n",
        "      precision = precision_score (test_Y, pred_y, average='weighted')\n",
        "      recall = recall_score (test_Y, pred_y, average='macro')\n",
        "      f1score = f1_score (test_Y, pred_y, average='weighted')\n",
        "      \n",
        "      plt.figure(figsize=figsize)\n",
        "      plt.subplots_adjust(hspace=0.5)\n",
        "      ax = plt.subplot()\n",
        "      sns.heatmap(results, annot=True, ax = ax, cmap='Blues', fmt='g', cbar=False)\n",
        "\n",
        "      ax.set_xlabel (xlabel)\n",
        "      ax.set_ylabel (ylabel)\n",
        "      ax.set_title (title + ': ' + name)\n",
        "      ax.xaxis.set_ticklabels (tickLabels)\n",
        "      ax.yaxis.set_ticklabels (tickLabels)\n",
        "\n",
        "      metrics_summary [name] = {\n",
        "          'accuracy' : accuracy,\n",
        "          'precision' : precision,\n",
        "          'recall' : recall,\n",
        "          'f1score' : f1score,\n",
        "          'delta': delta\n",
        "      }\n",
        "\n",
        "      bar()\n",
        "\n",
        "  print (\"\\nConfusion Matrices...\\n\")"
      ],
      "metadata": {
        "id": "-g93EL_2SH58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "Review Accuracy, Precision, Recall, F1-score and Execution Time"
      ],
      "metadata": {
        "id": "59fQJaV7TKDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if classification_widget.result != selected_classification:\n",
        "  print ('Classification has been changed.\\nRun the \\'Preprocessing\\' section again.')\n",
        "else:\n",
        "  print(\"{:<10} {:<8}\\t{:<8}\\t{:<8}\\t{:<8}\\t{:<20}\".format('Name', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'Execution Time'))\n",
        "\n",
        "  for key, value in metrics_summary.items():\n",
        "    print(\"{:<10} {:.2f} %\\t{:.2f} % \\t{:.2f} % \\t{:.2f} % \\t{:.2f} secs\".format(key, value['accuracy'] * 100, value['precision'] * 100, value['recall'] * 100, value['f1score'] * 100, value['delta']))"
      ],
      "metadata": {
        "id": "uKxgC4XQpy-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}